# Garbage Collection - EstratÃ©gia de Vagas Fantasmas

## ğŸš¨ O Problema das "Vagas Fantasmas"

### CenÃ¡rio Real:
1. **Segunda-feira:** Wildlife Studios publica vaga "Senior 3D Artist"
2. **Script roda:** Vaga Ã© salva no Supabase com `status = 'ativa'`
3. **Quarta-feira:** Wildlife fecha a vaga (preenchida ou cancelada)
4. **Script roda novamente:** API da Wildlife **nÃ£o retorna mais essa vaga**
5. **Resultado:** Vaga continua `status = 'ativa'` no seu banco **para sempre** âŒ

### Por que isso acontece?

Os fetchers atuais apenas fazem **INSERT** ou **UPDATE**:

```javascript
// âŒ PROBLEMA: Apenas processa o que vem da API
for (const job of apiJobs) {
  await supabase
    .from('jobs')
    .upsert({
      id: job.id,
      status: 'ativa',
      // ... outros campos
    });
}

// âŒ Vagas que NÃƒO vieram da API ficam Ã³rfÃ£s!
```

**ConsequÃªncia:** Seu site mostra vagas que nÃ£o existem mais, candidatos se frustram, sua credibilidade cai.

---

## âœ… A SoluÃ§Ã£o: Sync Sessions

### Conceito

Cada execuÃ§Ã£o do fetcher Ã© uma "sessÃ£o de sincronizaÃ§Ã£o" com ID Ãºnico. Apenas as vagas **tocadas** nessa sessÃ£o permanecem ativas.

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. InÃ­cio da Sync Session                           â”‚
â”‚    sync_id = UUID.generate()                        â”‚
â”‚    timestamp = now()                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Processar Cada Vaga da API                       â”‚
â”‚    upsert({                                         â”‚
â”‚      ...job_data,                                   â”‚
â”‚      sync_id: sync_id,         â† Marca como "viva" â”‚
â”‚      last_synced_at: timestamp                      â”‚
â”‚    })                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Garbage Collection (Final da SessÃ£o)            â”‚
â”‚    UPDATE jobs                                      â”‚
â”‚    SET status = 'closed'                            â”‚
â”‚    WHERE company_id = 'wildlife-studios'            â”‚
â”‚      AND sync_id != current_sync_id                 â”‚
â”‚      AND status = 'ativa'                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ ImplementaÃ§Ã£o

### Passo 1: Atualizar Schema do Supabase

```sql
-- Adicionar colunas para Garbage Collection
ALTER TABLE jobs
ADD COLUMN IF NOT EXISTS sync_id UUID,
ADD COLUMN IF NOT EXISTS last_synced_at TIMESTAMPTZ DEFAULT NOW();

-- Ãndice para performance na query de GC
CREATE INDEX IF NOT EXISTS idx_jobs_sync_id ON jobs(sync_id);
CREATE INDEX IF NOT EXISTS idx_jobs_company_status ON jobs(company_id, status);
```

### Passo 2: Modificar Fetchers

#### Antes (âŒ Sem GC):
```javascript
async function fetchJobs() {
  const jobs = await fetchFromAPI();
  
  for (const job of jobs) {
    await supabase.from('jobs').upsert(normalizeJob(job));
  }
  
  console.log('âœ… Done!');
}
```

#### Depois (âœ… Com GC):
```javascript
import { randomUUID } from 'node:crypto';

async function fetchJobs() {
  // 1. Criar Sync Session
  const syncId = randomUUID();
  const syncTimestamp = new Date().toISOString();
  
  console.log(`ğŸ”„ Starting Sync Session: ${syncId}`);
  
  // 2. Processar vagas (marca com sync_id)
  const jobs = await fetchFromAPI();
  const processedIds = [];
  
  for (const job of jobs) {
    const normalized = normalizeJob(job);
    
    await supabase.from('jobs').upsert({
      ...normalized,
      sync_id: syncId,              // â† Marca como "tocada"
      last_synced_at: syncTimestamp,
      status: 'ativa',
    });
    
    processedIds.push(normalized.id);
  }
  
  console.log(`âœ… Processed ${processedIds.length} jobs`);
  
  // 3. Garbage Collection
  await garbageCollectJobs(syncId, 'wildlife-studios');
}

/**
 * Mark jobs that weren't in this sync as closed
 */
async function garbageCollectJobs(currentSyncId, companyId) {
  console.log(`ğŸ—‘ï¸  Running Garbage Collection for ${companyId}...`);
  
  const { data, error } = await supabase
    .from('jobs')
    .update({ 
      status: 'closed',
      closed_at: new Date().toISOString(),
    })
    .eq('company_id', companyId)
    .eq('status', 'ativa')
    .neq('sync_id', currentSyncId);
  
  if (error) {
    console.error('âŒ GC Error:', error);
    return;
  }
  
  console.log(`ğŸ—‘ï¸  Closed ${data?.length || 0} stale jobs`);
}
```

---

## ğŸ“Š Exemplo de Fluxo Completo

### Dia 1: Primeira Sync
```
API retorna:
- job-001 (3D Artist)
- job-002 (Animator)
- job-003 (Engineer)

Banco apÃ³s sync (sync_id = aaa-111):
id       | status  | sync_id
---------|---------|----------
job-001  | ativa   | aaa-111
job-002  | ativa   | aaa-111
job-003  | ativa   | aaa-111
```

### Dia 2: Segunda Sync (job-002 foi fechada)
```
API retorna:
- job-001 (3D Artist)
- job-003 (Engineer)
- job-004 (Designer) â† NOVA

Processamento (sync_id = bbb-222):
1. Upsert job-001 â†’ sync_id = bbb-222
2. Upsert job-003 â†’ sync_id = bbb-222
3. Upsert job-004 â†’ sync_id = bbb-222 (nova)

Garbage Collection:
UPDATE jobs SET status = 'closed'
WHERE company_id = 'wildlife-studios'
  AND status = 'ativa'
  AND sync_id != 'bbb-222'
  
â†’ Fecha job-002 (sync_id ainda Ã© aaa-111)

Banco apÃ³s GC:
id       | status  | sync_id  | closed_at
---------|---------|----------|------------------
job-001  | ativa   | bbb-222  | null
job-002  | closed  | aaa-111  | 2025-01-16T10:00
job-003  | ativa   | bbb-222  | null
job-004  | ativa   | bbb-222  | null
```

---

## ğŸ¯ EstratÃ©gias AvanÃ§adas

### 1. Grace Period (PerÃ­odo de TolerÃ¢ncia)

Evita fechar vagas por falhas temporÃ¡rias da API:

```javascript
// SÃ³ fecha vagas que nÃ£o foram sincronizadas hÃ¡ mais de 7 dias
await supabase
  .from('jobs')
  .update({ status: 'closed' })
  .eq('company_id', companyId)
  .eq('status', 'ativa')
  .lt('last_synced_at', new Date(Date.now() - 7 * 24 * 60 * 60 * 1000).toISOString());
```

**Vantagem:** Protege contra:
- API temporariamente fora
- Rate limiting
- Erros de rede

**Desvantagem:** Vagas fechadas demoram atÃ© 7 dias para sumir

### 2. Soft Delete (Arquivar ao invÃ©s de fechar)

```javascript
// Ao invÃ©s de status = 'closed', use 'archived'
await supabase
  .from('jobs')
  .update({ 
    status: 'archived',
    archived_at: new Date().toISOString(),
  })
  .eq('company_id', companyId)
  .neq('sync_id', currentSyncId);

// Frontend filtra: WHERE status NOT IN ('closed', 'archived')
```

**Vantagem:** HistÃ³rico de vagas para analytics

### 3. Multi-Source Reconciliation

Se vocÃª busca a mesma vaga de mÃºltiplas fontes (ex: vaga no site + vaga no Remotive):

```javascript
// Marca vaga como "vista" em qualquer fonte
await supabase
  .from('job_sources')
  .upsert({
    job_id: jobId,
    source: 'remotive',
    sync_id: syncId,
    last_seen_at: now(),
  });

// SÃ³ fecha se NENHUMA fonte viu a vaga
await supabase.rpc('close_jobs_not_seen_anywhere', { sync_id: syncId });
```

---

## ğŸ§ª Como Testar

### Teste 1: Simular Vaga Fechada

```javascript
// 1. Rodar fetcher normalmente
node scripts/fetch-greenhouse-jobs.mjs

// 2. No Supabase, obter um job_id
// SELECT id, title, sync_id FROM jobs LIMIT 1;

// 3. Manualmente remover do resultado da API (editar script)
const jobs = apiJobs.filter(j => j.id !== 'JOB_ID_TO_TEST');

// 4. Rodar fetcher novamente
node scripts/fetch-greenhouse-jobs.mjs

// 5. Verificar que a vaga foi fechada
// SELECT * FROM jobs WHERE id = 'JOB_ID_TO_TEST';
// â†’ status deve ser 'closed'
```

### Teste 2: Verificar Logs

```bash
node scripts/fetch-greenhouse-jobs.mjs

# Output esperado:
# ğŸ”„ Starting Sync Session: 123e4567-e89b-12d3-a456-426614174000
# âœ… Processed 15 jobs
# ğŸ—‘ï¸  Running Garbage Collection for wildlife-studios...
# ğŸ—‘ï¸  Closed 3 stale jobs
```

---

## âš ï¸ Cuidados Importantes

### 1. Company-Specific GC
```javascript
// âŒ ERRADO: Fecha vagas de TODAS as empresas
await supabase.from('jobs').update({ status: 'closed' });

// âœ… CERTO: SÃ³ fecha vagas da empresa sendo sincronizada
await supabase
  .from('jobs')
  .update({ status: 'closed' })
  .eq('company_id', 'wildlife-studios'); // â† CRÃTICO!
```

### 2. Status Transitions
```javascript
// âŒ ERRADO: Pode reabrir vagas manualmente fechadas
.eq('status', 'ativa')

// âœ… CERTO: SÃ³ fecha vagas que estavam ativas
.in('status', ['ativa', 'pending_approval'])
```

### 3. Sync Frequency

```javascript
// Se rodar muito frequente (< 1 hora), use grace period
const GRACE_PERIOD_HOURS = 2;

await supabase
  .from('jobs')
  .update({ status: 'closed' })
  .neq('sync_id', currentSyncId)
  .lt('last_synced_at', 
    new Date(Date.now() - GRACE_PERIOD_HOURS * 60 * 60 * 1000).toISOString()
  );
```

---

## ğŸ“‹ Checklist de ImplementaÃ§Ã£o

### Schema Changes:
- [ ] Adicionar coluna `sync_id UUID` na tabela `jobs`
- [ ] Adicionar coluna `last_synced_at TIMESTAMPTZ` na tabela `jobs`
- [ ] Adicionar coluna `closed_at TIMESTAMPTZ` na tabela `jobs`
- [ ] Criar Ã­ndices para performance (`sync_id`, `company_id + status`)

### Fetcher Changes:
- [ ] Gerar `sync_id` no inÃ­cio de cada execuÃ§Ã£o
- [ ] Adicionar `sync_id` e `last_synced_at` em todos os upserts
- [ ] Implementar funÃ§Ã£o `garbageCollectJobs()`
- [ ] Chamar GC no final de cada fetcher
- [ ] Adicionar logs de GC (quantas vagas fechadas)

### Testing:
- [ ] Testar GC com vaga removida manualmente
- [ ] Verificar que apenas a empresa correta Ã© afetada
- [ ] Confirmar que vagas 'closed' nÃ£o sÃ£o reabertas
- [ ] Testar grace period se implementado

### Monitoring:
- [ ] Log do sync_id em cada execuÃ§Ã£o
- [ ] Contagem de vagas processadas
- [ ] Contagem de vagas fechadas por GC
- [ ] Alertas se muitas vagas fechadas de uma vez (possÃ­vel bug)

---

## ğŸ¯ PrÃ³ximos Passos

1. **Atualizar schema do Supabase** com novas colunas
2. **Modificar os 3 fetchers** (Greenhouse, Lever, Ashby) para incluir sync_id
3. **Testar com uma empresa** (ex: Wildlife Studios)
4. **Monitorar logs** para ver quantas vagas sÃ£o fechadas
5. **Considerar grace period** se houver falsos positivos

---

## ğŸ“š ReferÃªncias

- **Soft Deletes:** https://en.wikipedia.org/wiki/Soft_delete
- **ETL Best Practices:** Sync sessions sÃ£o padrÃ£o em pipelines de dados
- **IdempotÃªncia:** Garantir que executar o script 2x nÃ£o causa problemas

---

## ğŸ› Troubleshooting

### Problema: Muitas vagas sendo fechadas
**Causa:** API retornou menos vagas que o normal (rate limit, bug)

**SoluÃ§Ã£o:**
```javascript
// Adicionar validaÃ§Ã£o antes do GC
const minExpectedJobs = 10; // Wildlife normalmente tem 15+ vagas

if (processedIds.length < minExpectedJobs) {
  console.warn('âš ï¸  Too few jobs processed, skipping GC');
  return;
}
```

### Problema: Vagas nÃ£o estÃ£o sendo fechadas
**Causa:** Filtro errado na query de GC

**SoluÃ§Ã£o:**
```javascript
// Debug: Mostrar quais vagas seriam fechadas
const { data } = await supabase
  .from('jobs')
  .select('id, title, sync_id')
  .eq('company_id', companyId)
  .neq('sync_id', currentSyncId);

console.log('Would close:', data);
```

### Problema: Vaga reaparece depois de fechada
**Causa:** Empresa republicou a vaga com mesmo ID

**SoluÃ§Ã£o:** Isso Ã© comportamento correto! A vaga foi reaberta.

---

## âœ… Status Atual

**ImplementaÃ§Ã£o:** âŒ NÃƒO IMPLEMENTADO nos fetchers atuais

**Prioridade:** ğŸ”´ ALTA (problema crÃ­tico de UX)

**PrÃ³xima aÃ§Ã£o:** Atualizar schema do Supabase e modificar fetchers

